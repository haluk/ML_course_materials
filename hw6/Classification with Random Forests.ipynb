{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease Classification with a Random Forest \n",
    "\n",
    "In this assignment, we will go back to the problem of predicting presence of heart disease. In the first homework, we had used a decision tree classifier. We will see if we can have better classification performance with Random Forests. We will use the same [heart disease](http://archive.ics.uci.edu/ml/datasets/heart+Disease) dataset.\n",
    "\n",
    "A RandomForest classifier builds different decision trees for subsets of the examples in the dataset. Sampling is done with replacement, hence the subsets can overlap. For the final prediction each decision tree votes and majority decision becomes the final prediction.\n",
    "\n",
    "RandomForest classifier has many hyperparameters that can be tuned to improve performance. A list is available [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn-ensemble-randomforestclassifier). We will use grid search with cross-validation to try different parameter settings. In a grid search, different models are fit for different configurations of hyperparameters. For example, assume model *M* has 2 tunable hyperparameters *a* and *b*. Assuming each of the hyperparameters take on 2 possible values, our grid search will evaluate 4 models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesary imports\n",
    "import Orange\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`heart_disease` dataset is provided in Orange library. We load the dataset, extract the features and labels here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = Orange.data.Table('heart_disease')\n",
    "X =  heart_disease.X # get features\n",
    "y = heart_disease.Y # get labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has some examples with missing values for some of the features. We will impute these entries to the mean of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean') # initialize the imputer\n",
    "X = imp.fit_transform(X) # fill in the missing values with means of the feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change split our dataset into 67\\% train and 33\\% test set. We will do stratified sampling to keep the class distribution in both partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize and fit our random classifier. `max_depth` specifies the maximum depth of trees. `random_state` is set for reproducibility. Then, we test the classifier performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn` provides `GridSearchCV` class that implements grid search. We specify the parameters that we want to search over in a dictionary where the keys are the names of the hyperparameters of the estimator we are using (an instance of the `RandomForest` classifier in our case.  Performance of each configuration is evaluated using cross-validation. `refit` parameter in the initialization statement is to make the classifier run again with the best model found. Lastly, we report the accuracy for the best model found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_grid = {'n_estimators': range(10,200,10), 'max_depth': range(1, 20)}\n",
    "clf = GridSearchCV(rf, search_grid, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(max_depth=2, random_state=0),\n",
       "             param_grid={'max_depth': range(1, 20),\n",
       "                         'n_estimators': range(10, 200, 10)})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Available parameters that can be searched over are listed in the [`RandomForestClassifer` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn-ensemble-randomforestclassifier). Look at the defitions of the parameters below. Specify your own `search_grid`, perform grid search and report accuracy. \n",
    "\n",
    "Note: The set of all possible configurations will be the Cartesian product of the possible values you specify in the `search_grid` dictionary. If you search over 5 hyperparameters and each takes 3 possible values, `GridSearchCV` will fit and evaluate 5<sup>3</sup> = 243 models.\n",
    "\n",
    "- n_estimators\n",
    "- criterion\n",
    "- max_depth\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "- min_weight_fraction_leaf\n",
    "- max_features\n",
    "- max_leaf_nodes\n",
    "- min_impurity_decrease\n",
    "- min_impurity_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
